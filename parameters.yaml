mode: 'model_training'  #model_training #transfer_learning

transfer_learning_parameters:
  target_dataset: ['Madison'] 
  pretrained_model: ['Calce_1157']
  transfer_learning_technique: [2]
  patience: 50  
  epochs: 1000
  batch_size: 128
  validation_split: 0.2
  layer: 'bilstm'


data_parameters:
  training_datasets: ['LG','Calce','Madison']
  downsampling: True
  output_capacity: False 
  scale_test: True 
  output_time: False
  steps: 30 

model_parameters:
  input_dim: [30,3]
  steps: 30
  num_features: 3 
  dense_out: 1
  num_hidden_units_1: 20
  patience: 50
  epochs: 1000
  max_tuner: 70
  batch_size: 128
  validation_split: 0.2
  numberOfLayers: 2
  numberOfLSTMLayers: 4
  maxUnits: 64
  maxLSTMunits: 64
  stepLSTMunit: 8
  stepUnit: 4
  numberOfDenseLayers: 4
  maxDenseUnits: 64
  stepDenseUnit: 8
  maxDropout: 0.5
  dropoutRateStep: 0.1
  layer: 'bilstm' # Change Here 'lstm', 'bilstm', 'gru', 'bigru'
  objective_metric: 'mse'

